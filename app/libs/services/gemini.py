from typing import List, Dict

from fastapi import Depends

from app.libs.client import GeminiClient
from app.libs.services.chat import ChatHistoryService
from app.libs.services.pdf import PDFService
from app.models.chat import MessageDirection
from app.routers.pdf import get_pdf_service, db
from db import get_session


class ChatService:
    def __init__(self, db_session):
        self.llm_client = GeminiClient()
        self.chat_service =  ChatHistoryService(db_session)

    def build_messages(self, user_id: int, current_user_message: str, pdf_id: str) -> List[Dict[str, str]]:
        """
        Builds the message list to send to the Gemini model, including context from the selected PDF
        and the most recent user message if available.

        Args:
            user_id (int): The ID of the user.
            current_user_message (str): The current message from the user.
            pdf_id (int): The ID of the selected PDF document.

        Returns:
            List[Dict[str, str]]: A list of messages with roles and content for the model.
        """
        messages = []

        # System role defines the behavior of the model
        system_message = {
            "role": "system",
            "content": (
                "You are an AI assistant that helps users by answering questions based on a selected PDF document. "
                "Respond concisely and helpfully, and only use PDF content. If unsure, admit it."
            )
        }
        messages.append(system_message)


        # Add the parsed PDF content as context
        pdf_context = get_pdf_service().get_full_text(pdf_id, user_id)
        messages.append({
            "role": "user",
            "content": f"The content of the PDF is: {pdf_context}"
        })

        messages.append({"role": "user", "content": current_user_message})

        return messages

    def send_chat(self, user_id: int, current_user_message: str, pdf_id: str) -> str:
        """
        Sends a message to the Gemini model and returns the assistant's response.
        Stores the user and assistant messages in the conversation history.

        Args:
            user_id (int): The ID of the user.
            current_user_message (str): The current message from the user.
            pdf_id (int): The ID of the selected PDF document.

        Returns:
            str: The response generated by the assistant.

        Raises:
            RuntimeError: If an error occurs during message processing or model response.
        """
        try:
            self.chat_service.save_message(
                user_id=user_id,
                message=current_user_message,
                direction=MessageDirection.OUTGOING,
                pdf_hash=pdf_id
            )
            messages = self.build_messages(user_id, current_user_message, pdf_id)
            response = self.llm_client.chat(messages)
            self.chat_service.save_message(
                user_id=user_id,
                message=response,
                direction=MessageDirection.INCOMING,
                pdf_hash=pdf_id
            )

            return response
        except Exception as e:
            raise RuntimeError("An error occurred while processing your message.") from e
